import aiohttp
import asyncio
import json
import os
import random
import re
from datetime import datetime

# --- [ì„¤ì •] ---
API_KEY = "S14P02AR07-4c958e60-790d-49bd-9400-9fc7ccfe5776"
API_URL = "https://gms.ssafy.io/gmsapi/api.openai.com/v1/chat/completions"
OUTPUT_FILE = "qwen_0.5b_essential_data.jsonl"

# ëª©í‘œ: 3000ê°œ
TOTAL_TARGET_DATA = 1500
BATCH_SIZE = 10
CONCURRENT_REQUESTS = 5
MODEL_NAME = "gpt-4o"

def get_system_prompt(mode_index):
    """
    í•„ìˆ˜ ì •ë³´(ë‚˜ì´, ì„±ë³„, ì¦ìƒ) ìœ„ì£¼ì˜ ë°ì´í„° ìƒì„± í”„ë¡¬í”„íŠ¸
    """
    scenarios = [
        # [Case 1] ì™„ë²½í•œ ì •ë³´: í•„ìˆ˜ ì •ë³´ê°€ ë‹¤ ìˆëŠ” ê²½ìš°
        {
            "mode": "COMPLETE_INFO",
            "desc": "í™˜ìê°€ ìì‹ ì˜ ë‚˜ì´, ì„±ë³„, ì¦ìƒì„ ëª…í™•í•˜ê²Œ ë§í•˜ëŠ” ìƒí™©.",
            "prompt_guide": "ëª¨ë“  í•„ìˆ˜ í•„ë“œ(age, gender, symptoms)ê°€ ì±„ì›Œì§€ë„ë¡ ìƒì„±í•˜ì„¸ìš”."
        },
        # [Case 2] ì •ë³´ ëˆ„ë½: ì¦ìƒë§Œ ë§í•˜ëŠ” ê²½ìš° (ê°€ì¥ í”í•¨)
        {
            "mode": "SYMPTOM_ONLY",
            "desc": "í™˜ìê°€ ë„ˆë¬´ ê¸‰í•´ì„œ ì¦ìƒë§Œ ë§í•˜ê³  ë‚˜ì´/ì„±ë³„ì„ ë¹¼ë¨¹ì€ ìƒí™©.",
            "prompt_guide": "ageì™€ genderëŠ” ë°˜ë“œì‹œ nullë¡œ ë‘ê³ , symptomsë§Œ êµ¬ì²´ì ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”."
        },
        # [Case 3] ë³´í˜¸ì ì‹ ê³ : ì£¼ì–´ê°€ 'ìš°ë¦¬ ì•„ì´', 'ì•„ë¹ ' ë“±ì¸ ê²½ìš°
        {
            "mode": "CAREGIVER",
            "desc": "ë³´í˜¸ìê°€ ëŒ€ì‹  ì‹ ê³ í•˜ëŠ” ìƒí™©. ëŒ€ìƒì˜ ë‚˜ì´/ì„±ë³„ì„ ìœ ì¶”í•˜ê±°ë‚˜ ì–¸ê¸‰í•¨.",
            "prompt_guide": "is_selfë¥¼ falseë¡œ ì„¤ì •í•˜ê³ , ëŒ€ìƒì˜ ë‚˜ì´ëŒ€ì™€ ì„±ë³„ì„ ì¶”ì¶œí•˜ì„¸ìš”."
        },
        # [Case 4] ì„ íƒ ì •ë³´ í¬í•¨: íˆìŠ¤í† ë¦¬ë‚˜ íŠ¹ì´ì‚¬í•­ì´ ìˆëŠ” ê²½ìš°
        {
            "mode": "WITH_OPTIONAL",
            "desc": "ê¸°ì €ì§ˆí™˜(ë‹¹ë‡¨ ë“±)ì´ë‚˜ íŠ¹ì´ì‚¬í•­(ì„ì‹ , ìŒì£¼)ì„ í•¨ê»˜ ë§í•˜ëŠ” ìƒí™©.",
            "prompt_guide": "historyë‚˜ special_note í•„ë“œë¥¼ ì±„ìš°ì„¸ìš”."
        }
    ]
    
    current = scenarios[mode_index % 4]
    
    base_prompt = f"""
    ë‹¹ì‹ ì€ ì‘ê¸‰ ì˜ë£Œ AI í•™ìŠµ ë°ì´í„° ìƒì„±ê¸°ì…ë‹ˆë‹¤.
    í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤: **{current['mode']}** ({current['desc']})
    ìƒì„± ì§€ì¹¨: {current['prompt_guide']}

    [â˜… ë°ì´í„° ì¶”ì¶œ ê·œì¹™ (Strict Rules) â˜…]

    1. **í•„ìˆ˜ í•„ë“œ (Mandatory Fields)**
       - **age**: ì•„ë˜ êµ¬ê°„ ì¤‘ í•˜ë‚˜ë¡œ ë§¤í•‘ (ì •ë³´ ì—†ìœ¼ë©´ null)
         ["0-5", "5-10", "10-19", "20-30", "30-40", "40-50", "50-60", "60-70", "70-99"]
       - **gender**: "ë‚¨ì„±", "ì—¬ì„±" (ì •ë³´ ì—†ìœ¼ë©´ null)
       - **symptoms**: ["ë¶€ìœ„ ì¦ìƒ"] í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸ (í•„ìˆ˜!)
         * í¬ë§·: "ì•„í”ˆë¶€ìœ„ êµ¬ì²´ì ì¦ìƒ" (ë„ì–´ì“°ê¸° í•„ìˆ˜)
         * ì˜ˆ: "ë°°ê°€ ì°¢ì–´ì§ˆ ë“¯ ì•„íŒŒ" -> ["ë°° ê·¹ì‹¬í•œí†µì¦"]
         * ì˜ˆ: "ê°€ìŠ´ì´ ë‹µë‹µí•˜ê³  ìˆ¨ì´ ì•ˆ ì‰¬ì–´ì ¸" -> ["ê°€ìŠ´ ë‹µë‹µí•¨", "í˜¸í¡ê¸° í˜¸í¡ê³¤ë€"]
         * ì˜ˆ: "ë¨¸ë¦¬ê°€ í•‘ ëŒì•„" -> ["ë¨¸ë¦¬ ì–´ì§€ëŸ¬ì›€"]

    2. **ì„ íƒ í•„ë“œ (Optional Fields)**
       - **is_self**: true(ë³¸ì¸), false(íƒ€ì¸). (ì–¸ê¸‰ ì—†ìœ¼ë©´ ê¸°ë³¸ true)
       - **history**: ê³ í˜ˆì••, ë‹¹ë‡¨ ë“± ê¸°ì €ì§ˆí™˜. (ì—†ìœ¼ë©´ "íŠ¹ì´ì‚¬í•­ ì—†ìŒ")
       - **special_note**: ì„ì‹ , ìŒì£¼, ì•½ë¬¼, ìµœê·¼ìˆ˜ìˆ  ë“±. (ì—†ìœ¼ë©´ null)

    [ì¶œë ¥ í˜•ì‹]
    ì¡ë‹´ ì—†ì´ ì•„ë˜ JSON ë¦¬ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    [
      {{
        "text": "ìƒì„±ëœ ë°œí™” ë¬¸ì¥",
        "extraction": {{
          "age": "20-30",
          "gender": "ë‚¨ì„±",
          "symptoms": ["ë¨¸ë¦¬ ë‘í†µ", "ìœ„ì¥ êµ¬í† "],
          "is_self": true,
          "history": "íŠ¹ì´ì‚¬í•­ ì—†ìŒ",
          "special_note": "ìŒì£¼ ìƒíƒœ"
        }}
      }}
    ]

    ìœ„ ê·œì¹™ì— ë§ì¶° ë°ì´í„° {BATCH_SIZE}ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.
    """
    return base_prompt

async def fetch_batch(session, semaphore, mode_index):
    async with semaphore:
        prompt = get_system_prompt(mode_index)
        
        # ë‹¤ì–‘í•œ ì‘ê¸‰ í‚¤ì›Œë“œ ëœë¤ ì£¼ì…
        keywords = ["ë³µí†µ", "í‰í†µ", "ë‘í†µ", "ê³¨ì ˆ", "ì—´ìƒ(ë² ì„)", "í™”ìƒ", "ê³ ì—´", "í˜¸í¡ê³¤ë€", "ì•Œë ˆë¥´ê¸°", "ì•½ë¬¼ì¤‘ë…"]
        keyword = random.choice(keywords)

        payload = {
            "model": MODEL_NAME,
            "messages": [
                {"role": "system", "content": prompt},
                {"role": "user", "content": f"í‚¤ì›Œë“œ: '{keyword}'. ë¦¬ì–¼í•œ êµ¬ì–´ì²´ë¡œ ìƒì„±í•´."}
            ],
            "temperature": 0.95
        }
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {API_KEY}"
        }

        try:
            async with session.post(API_URL, json=payload, headers=headers, ssl=False) as response:
                if response.status != 200:
                    print(f"âš ï¸ Error {response.status}")
                    return []
                
                result = await response.json()
                content = result['choices'][0]['message']['content']
                
                cleaned = re.sub(r'^```json\s*', '', content, flags=re.MULTILINE)
                cleaned = re.sub(r'^```\s*', '', cleaned, flags=re.MULTILINE)
                cleaned = cleaned.replace("```", "").strip()
                
                try:
                    return json.loads(cleaned)
                except json.JSONDecodeError:
                    return []
        except Exception:
            return []

def save_to_jsonl(data_buffer):
    if not data_buffer: return

    with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
        for item in data_buffer:
            # 0.5B ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ìµœì¢… í¬ë§·
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì— 'í•„ìˆ˜'ì™€ 'ì„ íƒ'ì˜ ë‰˜ì•™ìŠ¤ë¥¼ ì‹¬ì–´ì¤ë‹ˆë‹¤.
            entry = {
                "messages": [
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ ì‘ê¸‰ ì˜ë£Œ AIì…ë‹ˆë‹¤. ë¬¸ì¥ì—ì„œ í•„ìˆ˜ ì •ë³´ {age, gender, symptoms}ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì¶œí•˜ê³ , ì„ íƒ ì •ë³´ {is_self, history, special_note}ëŠ” í™•ì¸ë˜ëŠ” ê²½ìš°ì—ë§Œ ì¶”ì¶œí•˜ì„¸ìš”."
                    },
                    {
                        "role": "user", 
                        "content": item['text']
                    },
                    {
                        "role": "assistant", 
                        "content": json.dumps(item['extraction'], ensure_ascii=False)
                    }
                ]
            }
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")
    print(f"ğŸ’¾ {len(data_buffer)}ê°œ ì €ì¥ ì™„ë£Œ.")

async def main():
    print(f"ğŸš€ Essential Data Generation Started (Target: {TOTAL_TARGET_DATA})")
    print(f"Mandatory: Age(Range), Gender, Symptoms(Body+State)")
    print(f"Optional: Is_self, History, Special_note")
    
    if not os.path.exists(OUTPUT_FILE):
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f: pass

    semaphore = asyncio.Semaphore(CONCURRENT_REQUESTS)
    
    async with aiohttp.ClientSession() as session:
        tasks = []
        loops = TOTAL_TARGET_DATA // BATCH_SIZE
        
        for i in range(loops):
            tasks.append(fetch_batch(session, semaphore, i % 4))
        
        total_saved = 0
        buffer = []
        
        for future in asyncio.as_completed(tasks):
            batch_data = await future
            if batch_data:
                buffer.extend(batch_data)
                
                if len(buffer) >= 50:
                    save_to_jsonl(buffer)
                    total_saved += len(buffer)
                    buffer = []
                    print(f"   (ì§„í–‰ë¥ : {total_saved}/{TOTAL_TARGET_DATA})")
        
        if buffer:
            save_to_jsonl(buffer)
            total_saved += len(buffer)

    print(f"\nğŸ‰ ì‘ì—… ë! {OUTPUT_FILE} ìƒì„± ì™„ë£Œ.")

if __name__ == "__main__":
    if os.name == 'nt':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ›‘ ì¤‘ë‹¨ë¨.")